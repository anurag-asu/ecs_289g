{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd39925-42b1-4841-9120-f268d6b8efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.8.0\n",
      "Eager mode:  True\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcbe1229-454c-46cc-98b4-fff243692e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bca83a3-732b-4eeb-967f-7d00fab67aa8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShapeChecker():\n",
    "    def __init__(self):\n",
    "        # Keep a cache of every axis-name seen\n",
    "        self.shapes = {}\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "              return\n",
    "\n",
    "        if isinstance(names, str):\n",
    "              names = (names,)\n",
    "\n",
    "        shape = tf.shape(tensor)\n",
    "        rank = tf.rank(tensor)\n",
    "\n",
    "        if rank != len(names):\n",
    "              raise ValueError(f'Rank mismatch:\\n'\n",
    "                       f'    found {rank}: {shape.numpy()}\\n'\n",
    "                       f'    expected {len(names)}: {names}\\n')\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            if isinstance(name, int):\n",
    "                old_dim = name\n",
    "            else:\n",
    "                old_dim = self.shapes.get(name, None)\n",
    "                new_dim = shape[i]\n",
    "\n",
    "            if (broadcast and new_dim == 1):\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # If the axis name is new, add its length to the cache.\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                             f\"    found: {new_dim}\\n\"\n",
    "                             f\"    expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a93cc6f-9c4e-4c04-ab62-fe545cdb050d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_words = ['Story Start', 'Story End']\n",
    "\n",
    "def load_data():\n",
    "    events = open('train_events.txt', 'rb').read().decode(encoding='utf-8')\n",
    "    events_sentences = open('train_sentences.txt', 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "    events = events.splitlines()\n",
    "    events_sentences = events_sentences.splitlines()\n",
    "\n",
    "    inp = [(event) for event in events if event not in bad_words]\n",
    "    targ = [(events_sentence) for events_sentence in events_sentences if events_sentence not in bad_words]\n",
    "\n",
    "    return targ, inp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6cafd8-8300-4960-9a72-4418f5e9a13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42130\n",
      "42130\n",
      "she decided whack at it \n",
      "So she decided to take a whack at it.\n"
     ]
    }
   ],
   "source": [
    "targ, inp = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8829ecd-1cb0-48a2-bc63-2cb6ec2254e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 12:58:55.516128: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-08 12:58:55.516483: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(inp)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f64e726-9e03-45c6-8e34-4fb19aa1d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "    # Split accecented characters.\n",
    "    # text = tf.convert_to_tensor(text)\n",
    "    # text = tf.convert_to_tensor(strip_accents(text))\n",
    "    text = tf.strings.lower(text)\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b24905d-458f-45bd-ada5-aa582d089bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] i had attended every lecture ,  no matter how boring it was . [END]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = tf.constant('I had attended every lecture, no matter how boring it was.')\n",
    "tf_lower_and_split_punct(example_text).numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d86cd6-056d-4877-988a-2fe0f1a93baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 15000\n",
    "\n",
    "input_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f481bf41-a681-4bf5-ba00-792fb883eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 12:59:03.706703: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-08 12:59:03.761064: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "input_text_processor.adapt(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b62d41-1d99-4b22-9501-47a3e65e05c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'na', '[START]', '[END]', 'he', 'she', 'was', 'it', 'in']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_processor.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9f0c50a-28a1-4760-8f76-486993aa39cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 12:59:17.714917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'the', 'to', 'a', 'was', 'he']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size)\n",
    "\n",
    "output_text_processor.adapt(targ)\n",
    "output_text_processor.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5ca5a0-5064-4731-9e9f-bb4d1fc03153",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab = np.array(input_text_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e15cf0ec-0059-4276-b298-bab6dd3b0846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Natalie was NA in love ' b'he sell it for price '\n",
      " b'Oscar was NA NA NA ' b'She decided pitcher of lemonade '\n",
      " b'NA confused NA NA NA '], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'The surf instructor was very attractive and Natalie fell in love.'\n",
      " b'Now he could sell it for a much higher price.'\n",
      " b'Oscar was a five year old boy.'\n",
      " b'She decided to make a pitcher of lemonade.' b'John was confused.'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for example_input_batch, example_target_batch in dataset.take(67):\n",
    "    print(example_input_batch[:5])\n",
    "    print()\n",
    "    print(example_target_batch[:5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb34d73d-a1d9-4447-be44-b830969d2264",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] natalie was na in love [END]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tokens = input_text_processor(example_input_batch)\n",
    "example_tokens[:3, :10]\n",
    "\n",
    "tokens = input_vocab[example_tokens[0].numpy()]\n",
    "' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ce0a771-5407-4be8-9ce7-62a58c9bdbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "\n",
    "        # The embedding layer converts tokens to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "\n",
    "        # The GRU RNN layer processes those vectors sequentially.\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   # Return the sequence and state\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "\n",
    "        # 2. The embedding layer looks up the embedding for each token.\n",
    "        vectors = self.embedding(tokens)\n",
    "\n",
    "        # 3. The GRU processes the embedding sequence.\n",
    "        #    output shape: (batch, s, enc_units)\n",
    "        #    state shape: (batch, enc_units)\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "\n",
    "        # 4. Returns the new sequence and its state.\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ebc5e42-089a-47b7-8473-735b63d8b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e482e304-fcaf-4f4d-bb9c-475d21340974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch, shape (batch): (64,)\n",
      "Input batch tokens, shape (batch, s): (64, 7)\n",
      "Encoder output, shape (batch, s, units): (64, 7, 1024)\n",
      "Encoder state, shape (batch, units): (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Convert the input text to tokens.\n",
    "example_tokens = input_text_processor(example_input_batch)\n",
    "\n",
    "# Encode the input sequence.\n",
    "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)\n",
    "example_enc_output, example_enc_state = encoder(example_tokens)\n",
    "\n",
    "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
    "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
    "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ab6076e-c5a6-4110-8342-0d6ef202f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        # For Eqn. (4), the  Bahdanau attention\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(query, ('batch', 't', 'query_units'))\n",
    "        shape_checker(value, ('batch', 's', 'value_units'))\n",
    "        shape_checker(mask, ('batch', 's'))\n",
    "\n",
    "        # From Eqn. (4), `W1@ht`.\n",
    "        w1_query = self.W1(query)\n",
    "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
    "\n",
    "        # From Eqn. (4), `W2@hs`.\n",
    "        w2_key = self.W2(value)\n",
    "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
    "\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            inputs = [w1_query, value, w2_key],\n",
    "            mask=[query_mask, value_mask],\n",
    "            return_attention_scores = True,\n",
    "        )\n",
    "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
    "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db92ce14-b09d-4adb-bc61-6ac69d15b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = BahdanauAttention(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09075ebc-f38e-42d2-95b4-853491ef2a09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch_size, query_seq_length, units):           (64, 2, 1024)\n",
      "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (64, 2, 7)\n"
     ]
    }
   ],
   "source": [
    "# Later, the decoder will generate this attention query\n",
    "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "\n",
    "context_vector, attention_weights = attention_layer(\n",
    "    query=example_attention_query,\n",
    "    value=example_enc_output,\n",
    "    mask=(example_tokens != 0))\n",
    "\n",
    "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
    "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82a64c04-d746-4e54-b031-a9543eaf89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderInput(typing.NamedTuple):\n",
    "    new_tokens: Any\n",
    "    enc_output: Any\n",
    "    mask: Any\n",
    "\n",
    "class DecoderOutput(typing.NamedTuple):\n",
    "    logits: Any\n",
    "    attention_weights: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d97447a-95a7-4a64-bb94-9b51940ddad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # For Step 1. The embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
    "                                                   embedding_dim)\n",
    "\n",
    "        # For Step 2. The RNN keeps track of what's been generated so far.\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        # For step 3. The RNN output will be the query for the attention layer.\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "        # For step 4. converting `ct` to `at`\n",
    "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
    "                                        use_bias=False)\n",
    "\n",
    "        # For step 5. This fully connected layer produces the logits for each\n",
    "        # output token.\n",
    "        self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
    "\n",
    "    def call(self,\n",
    "     inputs: DecoderInput,\n",
    "     state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
    "        \n",
    "\n",
    "        # Step 1. Lookup the embeddings\n",
    "        vectors = self.embedding(inputs.new_tokens)\n",
    "\n",
    "        # Step 2. Process one step with the RNN\n",
    "        rnn_output, state = self.gru(vectors, initial_state=state)\n",
    "\n",
    "\n",
    "        # Step 3. Use the RNN output as the query for the attention over the\n",
    "        # encoder output.\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
    "\n",
    "        # Step 4. Join the context_vector and rnn_output\n",
    "        #     [ct; ht] shape: (batch t, value_units + query_units)\n",
    "        context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
    "\n",
    "        # Step 4. tanh(Wc@[ct; ht])\n",
    "        attention_vector = self.Wc(context_and_rnn_output)\n",
    "\n",
    "        # Step 5. Generate logit predictions:\n",
    "        logits = self.fc(attention_vector)\n",
    "\n",
    "        return DecoderOutput(logits, attention_weights), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3a0cca1-6c85-433a-84c4-6286c79b5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                  embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "993af3c1-32a4-4b18-acde-eec0f2cecd8a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the target sequence, and collect the \"[START]\" tokens\n",
    "example_output_tokens = output_text_processor(example_target_batch)\n",
    "\n",
    "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
    "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dceea682-82ec-4567-a6a4-bdf567fc18d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: (batch_size, t, output_vocab_size) (64, 1, 14251)\n",
      "state shape: (batch_size, dec_units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Run the decoder\n",
    "dec_result, dec_state = decoder(\n",
    "    inputs = DecoderInput(new_tokens=first_token,\n",
    "                          enc_output=example_enc_output,\n",
    "                          mask=(example_tokens != 0)),\n",
    "    state = example_enc_state\n",
    ")\n",
    "\n",
    "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
    "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1e731be-3776-4e9f-8120-f092eeecb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebdef982-6679-40c3-b391-6f3ba733ee50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['melodies'],\n",
       "       ['celebration'],\n",
       "       ['casserole'],\n",
       "       ['oak'],\n",
       "       ['walton']], dtype='<U20')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(output_text_processor.get_vocabulary())\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "first_word[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a45426fe-ab89-4bde-9f56-16d9262c4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_result, dec_state = decoder(\n",
    "    DecoderInput(sampled_token,\n",
    "                 example_enc_output,\n",
    "                 mask=(example_tokens != 0)),\n",
    "    state=dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f43ce54f-fd5e-4e62-a522-0a485733ff0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['sidelines'],\n",
       "       ['graders'],\n",
       "       ['make'],\n",
       "       ['combs'],\n",
       "       ['sausage']], dtype='<U20')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
    "first_word = vocab[sampled_token.numpy()]\n",
    "first_word[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e06f8f62-d63d-4ba6-b1d6-8376bb162fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self):\n",
    "    self.name = 'masked_loss'\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "\n",
    "  def __call__(self, y_true, y_pred):\n",
    "\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss = self.loss(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44e0cdbb-1afc-4617-998b-aa494b7e30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTranslator(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units,\n",
    "               input_text_processor,\n",
    "               output_text_processor, \n",
    "               use_tf_function=True):\n",
    "        super().__init__()\n",
    "        # Build the encoder and decoder\n",
    "        encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "        decoder = Decoder(output_text_processor.vocabulary_size(),\n",
    "                          embedding_dim, units)\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        self.use_tf_function = use_tf_function\n",
    "        self.shape_checker = ShapeChecker()\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        self.shape_checker = ShapeChecker()\n",
    "        if self.use_tf_function:\n",
    "            return self._tf_train_step(inputs)\n",
    "        else:\n",
    "            return self._train_step(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a9260f0-cded-454c-9bbc-669ee2d34253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(self, input_text, target_text):\n",
    "\n",
    "    # Convert the text to token IDs\n",
    "    input_tokens = self.input_text_processor(input_text)\n",
    "    target_tokens = self.output_text_processor(target_text)\n",
    "    # Convert IDs to masks.\n",
    "    input_mask = input_tokens != 0\n",
    "\n",
    "    target_mask = target_tokens != 0\n",
    "\n",
    "    return input_tokens, input_mask, target_tokens, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd629574-8133-403d-a4b1-5f7e795de7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTranslator._preprocess = _preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7c0602f-4a74-40da-a56f-593d1985d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_step(self, inputs):\n",
    "  input_text, target_text = inputs  \n",
    "\n",
    "  (input_tokens, input_mask,\n",
    "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
    "\n",
    "  max_target_length = tf.shape(target_tokens)[1]\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    # Encode the input\n",
    "    enc_output, enc_state = self.encoder(input_tokens)\n",
    "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
    "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
    "\n",
    "    # Initialize the decoder's state to the encoder's final state.\n",
    "    # This only works if the encoder and decoder have the same number of\n",
    "    # units.\n",
    "    dec_state = enc_state\n",
    "    loss = tf.constant(0.0)\n",
    "\n",
    "    for t in tf.range(max_target_length-1):\n",
    "      # Pass in two tokens from the target sequence:\n",
    "      # 1. The current input to the decoder.\n",
    "      # 2. The target for the decoder's next prediction.\n",
    "      new_tokens = target_tokens[:, t:t+2]\n",
    "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
    "                                             enc_output, dec_state)\n",
    "      loss = loss + step_loss\n",
    "\n",
    "    # Average the loss over all non padding tokens.\n",
    "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
    "\n",
    "  # Apply an optimization step\n",
    "  variables = self.trainable_variables \n",
    "  gradients = tape.gradient(average_loss, variables)\n",
    "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  # Return a dict mapping metric names to current value\n",
    "  return {'batch_loss': average_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e639284-abca-44f0-b70e-67c9de4a6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTranslator._train_step = _train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a97992d-fbb1-4bf5-bcee-9c959ee124fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
    "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
    "\n",
    "    # Run the decoder one step.\n",
    "    decoder_input = DecoderInput(new_tokens=input_token,\n",
    "                               enc_output=enc_output,\n",
    "                               mask=input_mask)\n",
    "\n",
    "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
    "    # `self.loss` returns the total for non-padded tokens\n",
    "    y = target_token\n",
    "    y_pred = dec_result.logits\n",
    "    step_loss = self.loss(y, y_pred)\n",
    "\n",
    "    return step_loss, dec_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d891c56-b37a-4ba4-aa42-b83bc2d45464",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTranslator._loop_step = _loop_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8aa5a26-3498-4923-b0f5-4e6b6e2909a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    "    use_tf_function=False)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f7b8329-2df6-49f9-90ba-6b27e01044c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.564582358673212"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(output_text_processor.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bebec72-f4b1-46f5-960a-844b1fe6f4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n",
      "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=8.689249>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "for n in range(1):\n",
    "    print(translator.train_step([example_input_batch, example_target_batch]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07940522-e379-4e35-94a7-48d5f273b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
    "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
    "def _tf_train_step(self, inputs):\n",
    "    return self._train_step(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83c17d44-5df6-44b4-854d-c7811bcc6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTranslator._tf_train_step = _tf_train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07c29885-eeba-415c-bd05-09279fd72279",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator.use_tf_function = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "350ecfd6-0eee-4f54-9f5f-60bd8fb67f0d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 18:19:45.588800: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-05 18:19:45.675983: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] function_optimizer failed: INVALID_ARGUMENT: Input 6 of node gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/PartitionedCall was passed variant from gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/TensorListPopBack_2:1 incompatible with expected float.\n",
      "2022-03-05 18:19:45.769522: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] tfg_optimizer{} failed: INVALID_ARGUMENT: Input 6 of node gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/PartitionedCall was passed variant from gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/TensorListPopBack_2:1 incompatible with expected float.\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2022-03-05 18:19:45.779253: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] function_optimizer failed: INVALID_ARGUMENT: Input 6 of node gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/PartitionedCall was passed variant from gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/TensorListPopBack_2:1 incompatible with expected float.\n",
      "2022-03-05 18:19:45.832358: W tensorflow/core/common_runtime/process_function_library_runtime.cc:932] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Input 1 of node while/body/_1/while/TensorListPushBack_56 was passed float from while/body/_1/while/decoder_1/gru_3/PartitionedCall:6 incompatible with expected variant.\n",
      "2022-03-05 18:19:46.109960: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-05 18:19:46.251512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-05 18:19:48.210900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-05 18:19:50.788918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=8.714791>}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.train_step([example_input_batch, example_target_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a465f088-f9ca-491e-a209-9117b1a2fc78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# losses = []\n",
    "# for n in range(100):\n",
    "#     print('.', end='')\n",
    "#     logs = translator.train_step([example_input_batch, example_target_batch])\n",
    "#     losses.append(logs['batch_loss'].numpy())\n",
    "\n",
    "# print()\n",
    "# plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c61e093a-7d04-4b69-990e-fa62bf878426",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_translator = TrainTranslator(\n",
    "    embedding_dim, units,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor)\n",
    "\n",
    "# Configure the loss and optimizer\n",
    "train_translator.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=MaskedLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5139b9c0-4baa-42db-b548-9b4dc97f81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"training_stories/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8fff37b8-60b4-48cc-b595-d37274556842",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLogs(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.logs = []\n",
    "\n",
    "    def on_train_batch_end(self, n, logs):\n",
    "        self.logs.append(logs[self.key])\n",
    "\n",
    "batch_loss = BatchLogs('batch_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a739b6b1-9fcc-46cf-806b-5a0494fe0c35",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/659 [..............................] - ETA: 41:14 - batch_loss: 8.5263"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#decide epochs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_translator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbatch_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#decide epochs\n",
    "train_translator.fit(dataset, epochs=1,\n",
    "                     callbacks=[batch_loss, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15fb2253-1928-4521-b5b8-57ae6ff9e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "\n",
    "  def __init__(self, encoder, decoder, input_text_processor,\n",
    "               output_text_processor):\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.input_text_processor = input_text_processor\n",
    "    self.output_text_processor = output_text_processor\n",
    "\n",
    "    self.output_token_string_from_index = (\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=output_text_processor.get_vocabulary(),\n",
    "            mask_token='',\n",
    "            invert=True))\n",
    "\n",
    "    # The output should never generate padding, unknown, or start.\n",
    "    index_from_string = tf.keras.layers.StringLookup(\n",
    "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
    "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
    "\n",
    "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool_)\n",
    "    token_mask[np.array(token_mask_ids)] = True\n",
    "    self.token_mask = token_mask\n",
    "\n",
    "    self.start_token = index_from_string(tf.constant('[START]'))\n",
    "    self.end_token = index_from_string(tf.constant('[END]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6ee461d-5a89-48c4-b2b6-f773c8bfe1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_translator = Translator(\n",
    "    encoder=train_translator.encoder,\n",
    "    decoder=train_translator.decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cf9732e-c403-4527-9b2b-65b5311b8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(self, result_tokens):\n",
    "  shape_checker = ShapeChecker()\n",
    "  shape_checker(result_tokens, ('batch', 't'))\n",
    "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
    "  shape_checker(result_text_tokens, ('batch', 't'))\n",
    "\n",
    "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
    "                                       axis=1, separator=' ')\n",
    "  shape_checker(result_text, ('batch'))\n",
    "\n",
    "  result_text = tf.strings.strip(result_text)\n",
    "  shape_checker(result_text, ('batch',))\n",
    "  return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "563ead95-c65f-495a-8b3d-d503f1df8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.tokens_to_text = tokens_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0434337-0183-4e36-a925-dc7193b6050a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'boldly itself', b'discourage refusing', b'favorite acts',\n",
       "       b'banged jump', b'expand unruly'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_output_tokens = tf.random.uniform(\n",
    "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
    "    maxval=output_text_processor.vocabulary_size())\n",
    "text_translator.tokens_to_text(example_output_tokens).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bf430e5-5295-41ab-909e-f8d1b403d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(self, logits, temperature):\n",
    "  shape_checker = ShapeChecker()\n",
    "  # 't' is usually 1 here.\n",
    "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
    "  shape_checker(self.token_mask, ('vocab',))\n",
    "\n",
    "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
    "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
    "\n",
    "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
    "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
    "\n",
    "  if temperature == 0.0:\n",
    "    new_tokens = tf.argmax(logits, axis=-1)\n",
    "  else: \n",
    "    logits = tf.squeeze(logits, axis=1)\n",
    "    new_tokens = tf.random.categorical(logits/temperature,\n",
    "                                        num_samples=1)\n",
    "\n",
    "  shape_checker(new_tokens, ('batch', 't'))\n",
    "\n",
    "  return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c88b3db-37db-41c4-b1f4-cfcaea9b26e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.sample = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9ea3c9b-5533-4570-b0f1-94ade1081813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[8670],\n",
       "       [6648],\n",
       "       [3467],\n",
       "       [6831],\n",
       "       [5852]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
    "example_output_tokens = text_translator.sample(example_logits, temperature=1.0)\n",
    "example_output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c72cbb1f-6a57-487f-8ce1-b52f47d21b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_unrolled(self,\n",
    "                       input_text, *,\n",
    "                       max_length=50,\n",
    "                       return_attention=True,\n",
    "                       temperature=1.0):\n",
    "  batch_size = tf.shape(input_text)[0]\n",
    "  input_tokens = self.input_text_processor(input_text)\n",
    "  enc_output, enc_state = self.encoder(input_tokens)\n",
    "\n",
    "  dec_state = enc_state\n",
    "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "\n",
    "  result_tokens = []\n",
    "  attention = []\n",
    "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "\n",
    "  for _ in range(max_length):\n",
    "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
    "                             enc_output=enc_output,\n",
    "                             mask=(input_tokens!=0))\n",
    "\n",
    "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
    "\n",
    "    attention.append(dec_result.attention_weights)\n",
    "\n",
    "    new_tokens = self.sample(dec_result.logits, temperature)\n",
    "\n",
    "    # If a sequence produces an `end_token`, set it `done`\n",
    "    done = done | (new_tokens == self.end_token)\n",
    "    # Once a sequence is done it only produces 0-padding.\n",
    "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
    "\n",
    "    # Collect the generated tokens\n",
    "    result_tokens.append(new_tokens)\n",
    "\n",
    "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "      break\n",
    "\n",
    "  # Convert the list of generates token ids to a list of strings.\n",
    "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
    "  result_text = self.tokens_to_text(result_tokens)\n",
    "\n",
    "  if return_attention:\n",
    "    attention_stack = tf.concat(attention, axis=1)\n",
    "    return {'text': result_text, 'attention': attention_stack}\n",
    "  else:\n",
    "    return {'text': result_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce8aea2f-78af-4420-937d-fa8836d77b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.translate = translate_unrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1988ed12-02e0-4db1-bc7b-b08670205b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base ua filling beverage elevation babysitter thirteenth pork afraid disfigured shares gave breathalyzer rumbled viewed confiscated nfl smoothly bats roast jonas switch biochemistry mover shampooing prairies oboe various advance danisha academic rewarding mathilda riveting mints brightened hoping design productive plunged picked downtown jumbo drywall races bala beijing depth walter bartending\n",
      "-----------\n",
      "darken reflecting frank rivals starbucks myrtle hornets subpar riding suso oclock receiver tatiana bee dangerously hugs rusty elmer buffet infatuated depth journals patients perimeter champagne jays vanessa vince online derek pan hundred record strawberry compete bike priority danielle diets hoarding shopper nitrous teresa fragile dances translation surrendered knocks unharmed homecooked\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = tf.constant([\n",
    "    'she showed appraisal In morning',\n",
    "    'he have time for process', \n",
    "])\n",
    "\n",
    "result = text_translator.translate(\n",
    "    input_text = input_text)\n",
    "\n",
    "print(result['text'][0].numpy().decode())\n",
    "print('-----------')\n",
    "print(result['text'][1].numpy().decode())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f5ac0-4304-423d-aec4-c3192ddc38bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
